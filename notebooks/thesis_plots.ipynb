{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "\n",
    "import traceback\n",
    "import numpy as np\n",
    "import scipy.stats as ss\n",
    "import yaml\n",
    "import itertools\n",
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "from os import path\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, TheilSenRegressor, RANSACRegressor, HuberRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "def printmd(*args):\n",
    "    display(Markdown(' '.join(map(str, args))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !ros2 run local_planning_performance_modelling compute_metrics -r \"~/ds/performance_modelling/output/test_local_planning_gen_circles/*\" -s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# !ros2 run local_planning_performance_modelling compute_metrics -r \"~/ds/performance_modelling/output/test_local_planning/*\" -s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "local_planner_color = {'dwa': 'blue', 'arena': 'orange', 'teb': 'green'}\n",
    "local_planner_symbol = {'dwa': 'o', 'arena': '^', 'teb': 'x'}\n",
    "robot_model_color = {'hunter': 'cyan', 'turtle': 'green'}\n",
    "pd.options.display.width = 200\n",
    "pd.options.display.max_rows = 0\n",
    "pd.options.display.float_format = '{:,.3f}'.format\n",
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "plt.rcParams['lines.linewidth'] = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/w/catkin_ws/src/local_planning_performance_modelling/notebooks/load_data.py:2\u001b[0m\n\u001b[0;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(path\u001b[38;5;241m.\u001b[39mexpanduser(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m~/ds/performance_modelling/output/local_planning/results.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path\u001b[38;5;241m.\u001b[39mexpanduser(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m~/ds/performance_modelling/output/local_planning/results_info.yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;28;01mas\u001b[39;00m results_info_file:\n\u001b[1;32m      4\u001b[0m     results_info \u001b[38;5;241m=\u001b[39m yaml\u001b[38;5;241m.\u001b[39msafe_load(results_info_file)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "%run load_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv(path.expanduser(\"~/ds/performance_modelling/output/local_planning/results.csv\"))\n",
    "# with open(path.expanduser(\"~/ds/performance_modelling/output/local_planning/results_info.yaml\")) as results_info_file:\n",
    "#     results_info = yaml.safe_load(results_info_file)\n",
    "\n",
    "# # df = pd.read_csv(path.expanduser(\"~/ds_alt/performance_modelling/output_plot_no_pedestrian_data/results.csv\"))\n",
    "# # with open(path.expanduser(\"~/ds_alt/performance_modelling/output_plot_no_pedestrian_data/results_info.yaml\")) as results_info_file:\n",
    "# #     results_info = yaml.safe_load(results_info_file)\n",
    "    \n",
    "# df.rename(inplace=True, columns={\n",
    "#     'collisionless_localization_update_absolute_translation_error_mean': 'absolute_translation_error',\n",
    "#     'collisionless_localization_update_absolute_rotation_error_mean': 'absolute_rotation_error',\n",
    "#     'collisionless_localization_update_normalized_relative_translation_error_mean': 'normalized_relative_translation_error',\n",
    "#     'collisionless_localization_update_normalized_relative_rotation_error_mean': 'normalized_relative_rotation_error',\n",
    "#     'localization_update_rate_mean': 'localization_update_rate',\n",
    "# })\n",
    "\n",
    "# # turn odometry_error into beta_1..4\n",
    "# results_info['run_parameter_names'] += ['beta_1', 'beta_2', 'beta_3', 'beta_4']\n",
    "# results_info['run_parameter_names'].remove('odometry_error')\n",
    "# for i in range(0, 4):\n",
    "#     df[f'beta_{i+1}'] = df['odometry_error'].apply(lambda x: eval(x)[i])\n",
    "# del df['odometry_error']\n",
    "\n",
    "# df.loc[df.robot_model == 'turtlebot3_waffle_performance_modelling', 'robot_model'] = 'turtle'\n",
    "\n",
    "# run_parameters = [c for c in list(df.columns) if c in results_info['run_parameter_names']]\n",
    "# run_parameters += ['max_steering_angle_deg']\n",
    "# metrics_versions = [c for c in list(df.columns) if '_version' in c]\n",
    "# everything_else = ['run_id', 'session_id', 'run_number', 'goal_index']\n",
    "# metrics = [c for c in df.columns if c not in metrics_versions + run_parameters + everything_else]\n",
    "# metrics_and_versions = [c for c in list(df.columns) if '_version' in c or c in metrics]\n",
    "\n",
    "# cpu_time_metrics = [c for c in metrics if 'cpu_time' in c]\n",
    "# max_memory_metrics = [c for c in metrics if 'max_memory' in c]\n",
    "\n",
    "# # add useful parameters\n",
    "# df['session_id'] =  df['run_id'].apply(lambda x:  x.split('_')[1]+'_'+x.split('_')[2]+'_'+x.split('_')[3])\n",
    "# df['run_number'] =  df['run_id'].apply(lambda x:  int(x.split('_')[5]))\n",
    "# df[max_memory_metrics] = df[max_memory_metrics]/1024**2\n",
    "# df['max_steering_angle_deg'] = 90    # crea una nuova colonna e riempie le righe con il valore 90\n",
    "# df[\"run_index_str\"] = df['run_index'].apply(lambda x: str(x))\n",
    "# df['goal_index'] = df.environment_name + '_' + df.run_index_str\n",
    "\n",
    "# # add metrics from existing ones\n",
    "# df['average_velocity'] = df['trajectory_length'] / df['execution_time']\n",
    "# df['success_rate'] = df['success_rate'] & (1 - df['collision_rate'])\n",
    "\n",
    "# metrics += ['average_velocity']\n",
    "# metrics_and_versions += ['average_velocity']\n",
    "\n",
    "# min_execution_time_group_df = df.groupby([\"environment_name\", \"run_index\", \"success_rate\"])\n",
    "# for (environment_name, run_index, success_rate), group_df in min_execution_time_group_df:\n",
    "#     df.loc[(df.environment_name == environment_name) & (df.run_index == run_index) & (success_rate), 'min_execution_time'] = group_df.execution_time.min()\n",
    "# df['norm_execution_time'] = df.execution_time / df.min_execution_time\n",
    "# metrics += ['norm_execution_time']\n",
    "# metrics_and_versions += ['norm_execution_time']\n",
    "\n",
    "# if True:\n",
    "#     printmd(\"## Number of Runs\")\n",
    "#     printmd(f\"    {len(df.run_id.unique())}\")\n",
    "\n",
    "#     printmd(\"## Run Parameters\")\n",
    "#     for name in [run_parameter_name for run_parameter_name in run_parameters if 'localization_generator_' not in run_parameter_name]:\n",
    "#         values = list(df[name].unique())\n",
    "#         printmd(f\"    {name:<70}\", sorted(values))\n",
    "\n",
    "#     printmd(\"## Metrics\")\n",
    "#     for name in metrics_and_versions:\n",
    "#         if name in metrics_versions:\n",
    "#             if len(df[name].unique()) == 1:\n",
    "#                 printmd(f\"    {name:<70} {sorted(df[name].unique())}\")\n",
    "#             else:\n",
    "#                 printmd(f\"<code><font style='background-color:yellow;font-family:monospace'>{name:<70}{sorted(df[name].unique())} </font></code> ⚠️\")\n",
    "#         else:\n",
    "#             printmd(f\"    {name:<70} min: {df[name].min(skipna=True):10.4g} {'avg':>15}: {df[name].mean(skipna=True):10.4g} {'max':>15}: {df[name].max(skipna=True):10.4g} {'nan':>15}: {sum(df[name].isna()):10.4g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.execution_time.agg(['mean', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.execution_time.mean() * 1400) / 3600 / 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.groupby(by=['include_costmap_obstacles', 'include_dynamic_obstacles', 'beta_1']).agg(['mean', 'count'])[['success_rate', 'move_base_cpu_time']].sort_values(by=('success_rate', 'mean'), ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "\n",
    "df_success_cpu_trade_off = df.groupby(by=['include_costmap_obstacles', 'include_dynamic_obstacles', 'beta_1']).agg('mean')[['success_rate', 'move_base_cpu_time']].sort_values(by='success_rate', ascending=False)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "x = list(df_success_cpu_trade_off.move_base_cpu_time)\n",
    "y = list(df_success_cpu_trade_off.success_rate)\n",
    "labels = list(df_success_cpu_trade_off.index)\n",
    "\n",
    "for x_i, y_i in zip(x, y):\n",
    "    plt.plot([x_i, x_i+100], [y_i, y_i], color='black', linewidth=1, alpha=0.5)\n",
    "    plt.plot([x_i, x_i], [-100, y_i], color='black', linewidth=1, alpha=0.5)\n",
    "\n",
    "for i, label in enumerate(labels):\n",
    "    ax.annotate(label, xy=(x[i], y[i]), xytext=(-24, 6) , xycoords='data', textcoords='offset points')\n",
    "\n",
    "ax.scatter(df_success_cpu_trade_off.move_base_cpu_time, df_success_cpu_trade_off.success_rate, label=', '.join(df_success_cpu_trade_off.index.names).replace('_', ' '))\n",
    "plt.xlabel('CPU time [s]')\n",
    "plt.ylabel('Success rate')\n",
    "plt.xlim([0, 1.1*df_success_cpu_trade_off.move_base_cpu_time.max()])\n",
    "plt.ylim([0, 1.1])\n",
    "plt.title(\"Trade-off between TEB parameter values\")\n",
    "\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.groupby(by=['min_turning_radius', 'include_costmap_obstacles', 'include_dynamic_obstacles']).agg(['mean', 'count'])[['success_rate', 'collision_rate', 'move_base_cpu_time', 'move_base_max_memory']].sort_values(by=('success_rate', 'mean'), ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for local_planner_node in df.local_planner_node.unique():\n",
    "    df_group = df[df.local_planner_node == local_planner_node].groupby(by='pedestrian_number')\n",
    "    # raggruppiamo in base alla x e fai la media del collision rate\n",
    "    df_success_rate = df_group.agg('mean').success_rate\n",
    "    \n",
    "    plt.plot(df_success_rate.index, df_success_rate, local_planner_symbol[local_planner_node] + '-', label=local_planner_node, color=local_planner_color[local_planner_node])\n",
    "    \n",
    "plt.xticks(sorted(list(set(range(0, 101, 20)).union(set([5])))))\n",
    "plt.legend()\n",
    "plt.xlabel('Pedestrian Number')\n",
    "plt.ylabel('Success Rate')\n",
    "plt.title('1) Pedestrian Number vs Success Rate')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for local_planner_node in df.local_planner_node.unique():\n",
    "    df_group = df[df.local_planner_node == local_planner_node].groupby(by='pedestrian_number')\n",
    "    # raggruppiamo in base alla x e fai la media del collision rate\n",
    "    df_collision_rate = df_group.agg('mean').collision_rate\n",
    "    \n",
    "    plt.plot(df_collision_rate.index, df_collision_rate, local_planner_symbol[local_planner_node] + '-', label=local_planner_node, color=local_planner_color[local_planner_node])\n",
    "    \n",
    "plt.xticks(sorted(list(set(range(0, 101, 20)).union(set([5])))))\n",
    "plt.legend()\n",
    "plt.xlabel('Pedestrian Number')\n",
    "plt.ylabel('Collision Rate')\n",
    "plt.title('1) Pedestrian Number vs Collision Rate')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for local_planner_node in df.local_planner_node.unique():\n",
    "    df_group = df[df.local_planner_node == local_planner_node].groupby(by='pedestrian_max_vel')\n",
    "    # raggruppiamo in base alla x e fai la media del collision rate\n",
    "    df_collision_rate = df_group.agg('mean').collision_rate\n",
    "    \n",
    "    plt.plot(df_collision_rate.index, df_collision_rate, local_planner_symbol[local_planner_node] + '-', label=local_planner_node, color=local_planner_color[local_planner_node])\n",
    "    \n",
    "plt.legend()\n",
    "plt.xlabel('Pedestrian Velocity')\n",
    "plt.ylabel('Collision Rate')\n",
    "plt.title('2) Pedestrian Velocity vs Collision Rate')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for local_planner_node in df.local_planner_node.unique():\n",
    "    df_group = df[df.local_planner_node == local_planner_node].groupby(by='pedestrian_number')\n",
    "    # raggruppiamo in base alla x e fai la media del collision rate\n",
    "    df_execution_time = df_group.agg('mean').execution_time\n",
    "    \n",
    "    plt.plot(df_execution_time.index, df_execution_time, local_planner_symbol[local_planner_node] + '-', label=local_planner_node, color=local_planner_color[local_planner_node])\n",
    "    \n",
    "plt.xticks(sorted(list(set(range(0, 101, 20)).union(set([5])))))\n",
    "plt.legend()\n",
    "plt.xlabel('Pedestrian Number')\n",
    "plt.ylabel('Execution Time')\n",
    "plt.title('3) Pedestrian Number vs Execution Time')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for local_planner_node in df.local_planner_node.unique():\n",
    "    df_group = df[df.local_planner_node == local_planner_node].groupby(by='pedestrian_max_vel')\n",
    "    # raggruppiamo in base alla x e fai la media del collision rate\n",
    "    df_execution_time = df_group.agg('mean').execution_time\n",
    "    \n",
    "    plt.plot(df_execution_time.index, df_execution_time, local_planner_symbol[local_planner_node] + '-', label=local_planner_node, color=local_planner_color[local_planner_node])\n",
    "    \n",
    "plt.legend()\n",
    "plt.xlabel('Pedestrian Velocity')\n",
    "plt.ylabel('Execution Time')\n",
    "plt.title('4) Pedestrian Velocity vs Execution time')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for local_planner_node in df.local_planner_node.unique():\n",
    "    df_group = df[df.local_planner_node == local_planner_node].groupby(by='pedestrian_number')\n",
    "    # raggruppiamo in base alla x e fai la media del collision rate\n",
    "    df_execution_time = df_group.agg('mean').trajectory_length\n",
    "    \n",
    "    plt.plot(df_execution_time.index, df_execution_time, local_planner_symbol[local_planner_node] + '-', label=local_planner_node, color=local_planner_color[local_planner_node])\n",
    "    \n",
    "plt.xticks(sorted(list(set(range(0, 101, 20)).union(set([5])))))    \n",
    "plt.legend()\n",
    "plt.xlabel('Pedestrian Velocity')\n",
    "plt.ylabel('Trajectory Length')\n",
    "plt.title('5) Pedestrian Velocity vs Trajectory Length')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "printmd(\"## Overall performance values by robot model, local planner component, kinematic constraints, and localization component\")\n",
    "printmd(\"### Considering all runs (sorted by collisionless success rate)\")\n",
    "df.groupby(['robot_model', 'local_planner_node', 'max_steering_angle_deg', 'localization_node'])[[\"success_rate\", \"collision_rate\", \"average_velocity\", \"norm_execution_time\"]].agg(['mean', 'count']).sort_values(('success_rate', 'mean'), ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "printmd(\"### Only considering successful runs (sorted by norm execution time)\")\n",
    "df[df.success_rate == 1].groupby(['robot_model', 'local_planner_node', 'max_steering_angle_deg', 'localization_node'])[[\"success_rate\", \"collision_rate\", \"average_velocity\", \"norm_execution_time\"]].agg(['mean', 'count']).sort_values(('norm_execution_time', 'mean'), ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "printmd(\"### Only considering failed runs (sorted by collision rate)\")\n",
    "df[df.success_rate == 0].groupby(['robot_model', 'local_planner_node', 'max_steering_angle_deg', 'localization_node'])[[\"success_rate\", \"collision_rate\", \"average_velocity\", \"norm_execution_time\"]].agg(['mean', 'count']).sort_values(('collision_rate', 'mean'), ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def bar_plot(metric_name, selected_df, y_columns=['local_planner_node'], percentage=False, unit_symbol=None, higher_better=True):\n",
    "    bar_df = selected_df.groupby(y_columns)[metric_name].agg(['mean', 'count']).sort_values(by=('mean'), ascending=higher_better)\n",
    "    ax = (bar_df.sort_values(by=('mean'), ascending=higher_better)* (100 if percentage else 1) ).plot.barh(y=[('mean')], stacked=True, figsize=[10, 5], grid=True, legend=False)\n",
    "    ax.set_xlabel(metric_name.replace('_', ' ').replace(',', ', ') + (f\" [{unit_symbol}]\" if unit_symbol else \"\"))\n",
    "    ax.set_ylabel(ax.get_ylabel().replace('_', ' ').replace(',', ',\\n'))\n",
    "    plt.gcf().set_size_inches([5, 1])\n",
    "    plt.show()\n",
    "# printmd(\"## success rate\")\n",
    "# bar_plot(metric_name='success_rate', selected_df=df[(df.max_steering_angle_deg == 90.0)], percentage=True, higher_better=True, unit_symbol='%')\n",
    "# printmd(\"## collision_rate\")\n",
    "# bar_plot(metric_name='collision_rate', selected_df=df[(df.max_steering_angle_deg == 90.0)], percentage=True, higher_better=False, unit_symbol='%')\n",
    "# printmd(\"## average_velocity, only successful runs\")\n",
    "# bar_plot(metric_name='average_velocity', selected_df=df[(df.success_rate == 1) & (df.max_steering_angle_deg == 90.0)], higher_better=True, unit_symbol='m/s')\n",
    "# printmd(\"## norm_execution_time, only successful runs\")\n",
    "# bar_plot(metric_name='norm_execution_time', selected_df=df[(df.success_rate == 1) & (df.max_steering_angle_deg == 90.0)], higher_better=False, unit_symbol='s/s')\n",
    "printmd(\"## teb only, success rate\")\n",
    "bar_plot(metric_name='success_rate', selected_df=df[(df.local_planner_node == 'teb')], y_columns=['include_costmap_obstacles', 'include_dynamic_obstacles'], percentage=True, higher_better=True, unit_symbol='%')\n",
    "printmd(\"## teb only, collision rate\")\n",
    "bar_plot(metric_name='collision_rate', selected_df=df[(df.local_planner_node == 'teb')], y_columns=['include_costmap_obstacles', 'include_dynamic_obstacles'], percentage=True, higher_better=True, unit_symbol='%')\n",
    "printmd(\"## teb only, cpu usage\")\n",
    "bar_plot(metric_name='system_max_memory', selected_df=df[(df.local_planner_node == 'teb')], y_columns=['include_costmap_obstacles', 'include_dynamic_obstacles'], higher_better=True, unit_symbol='Mb')\n",
    "printmd(\"## teb only, cpu time\")\n",
    "bar_plot(metric_name='move_base_cpu_time', selected_df=df[(df.local_planner_node == 'teb')], y_columns=['include_costmap_obstacles', 'include_dynamic_obstacles'], higher_better=True, unit_symbol='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "max_scatter_points = 200\n",
    "def plot_in_out_metrics_bin_width_save(output_metric, input_metrics, bin_widths, min_bin_count, selected_df, out_dir, min_y=0.0, plot_all=True, scatter=True):\n",
    "    max_y = -np.inf\n",
    "#     scatter = False\n",
    "\n",
    "    for i, (input_metric, bin_width) in enumerate(zip(input_metrics, bin_widths)):\n",
    "        fig = plt.figure()\n",
    "\n",
    "        for localization_node in df.localization_node.unique():\n",
    "            for local_planner_node in df.local_planner_node.unique():\n",
    "                \n",
    "                df_lr = selected_df[\n",
    "                    (selected_df.localization_node == localization_node) & \n",
    "                    (selected_df.local_planner_node == local_planner_node) & \n",
    "                    selected_df[input_metric.name].notna() & \n",
    "                    selected_df[output_metric.name].notna()\n",
    "                ].copy()\n",
    "                if len(df_lr[input_metric.name]):\n",
    "                    if scatter:\n",
    "                        n = max(1, int(len(df_lr[input_metric.name])/max_scatter_points))\n",
    "                        plt.scatter(df_lr[input_metric.name][::n], df_lr[output_metric.name][::n], marker='.', s=0.25, color=local_planner_color[local_planner_node])\n",
    "                    \n",
    "                    if bin_width is not None:\n",
    "                        if isinstance(bin_width, str):\n",
    "                            _, bins = np.histogram(df_lr[input_metric.name], bins=bin_width)\n",
    "                        else:\n",
    "                            bins = np.arange(0., input_metric.max() + bin_width, bin_width)\n",
    "\n",
    "                        df_lr['x_range'] = pd.cut(df_lr[input_metric.name], bins, labels=bins[:-1]).astype('float')\n",
    "                        df_lr_g = df_lr.groupby('x_range').agg(['mean', 'count'])\n",
    "                        df_lr_g = df_lr_g[ df_lr_g[(output_metric.name, 'count')] > min_bin_count ]\n",
    "                        plt.plot(df_lr_g.index, df_lr_g[(output_metric.name, 'mean')], f'{local_planner_symbol[local_planner_node]}-', fillstyle='none', mfc=None, label=f'{local_planner_node}', linewidth=1, color=local_planner_color[local_planner_node])\n",
    "                    else:\n",
    "                        df_lr_g = df_lr.groupby(input_metric.name).agg(['mean', 'count'])\n",
    "                        df_lr_g = df_lr_g[ df_lr_g[(output_metric.name, 'count')] > min_bin_count ]\n",
    "                        plt.plot(df_lr_g.index, df_lr_g[(output_metric.name, 'mean')], f'{local_planner_symbol[local_planner_node]}-', fillstyle='none', mfc=None, label=f'{local_planner_node}', linewidth=1, color=local_planner_color[local_planner_node])\n",
    "                    max_y = max(max_y, df_lr_g[(output_metric.name, 'mean')].max())\n",
    "\n",
    "        if i == 0:\n",
    "            plt.legend()\n",
    "        plt.grid()\n",
    "        plt.xlabel(input_metric.name.replace('_', ' '))\n",
    "        plt.ylabel(output_metric.name.replace('_', ' '))\n",
    "        plt.ylim([min_y, max_y*1.1])\n",
    "        fig.set_size_inches([4, 4])\n",
    "        if not path.exists(out_dir):\n",
    "            os.makedirs(out_dir)\n",
    "        fig.savefig(out_dir + f\"/{output_metric.name}---{input_metric.name}.pdf\".replace('_', '-'), bbox_inches='tight')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(by=['pedestrian_number', 'local_planner_node']).agg(['count', 'mean'])[['simulation_max_memory', 'simulation_cpu_time', 'system_cpu_time', 'system_max_memory', 'move_base_cpu_time', 'move_base_max_memory']].sort_values(by=('pedestrian_number'), ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[].groupby(by=['pedestrian_number', 'local_planner_node']).agg(['count', 'mean'])[['real_time_factor']].sort_values(by=('pedestrian_number'), ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df[df.local_planner_node == 'arena'][df.pedestrian_number == 100]['real_time_factor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.local_planner_node == 'teb'][df.pedestrian_number == 100][df.real_timefa]['real_time_factor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.real_time_factor > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.real_time_factor > 1].real_time_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import Markdown, display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "\n",
    "import traceback\n",
    "import numpy as np\n",
    "import scipy.stats as ss\n",
    "import yaml\n",
    "import itertools\n",
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "from os import path\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, TheilSenRegressor, RANSACRegressor, HuberRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "def printmd(*args):\n",
    "    display(Markdown(' '.join(map(str, args))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# !ros2 run local_planning_performance_modelling compute_metrics -r \"~/ds/performance_modelling/output/test_local_planning/*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !ros2 run local_planning_performance_modelling compute_metrics -r \"~/ds/performance_modelling/output/test_local_planning_gen_circles/*\" -s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "local_planner_color = {'dwb': 'blue', 'rpp': 'orange', 'teb': 'green', 'rpp_bad': 'yellow'}\n",
    "robot_model_color = {'hunter': 'cyan', 'turtle': 'green'}\n",
    "pd.options.display.width = 500\n",
    "pd.options.display.max_rows = 0\n",
    "pd.options.display.float_format = '{:,.3f}'.format\n",
    "plt.rcParams['figure.figsize'] = [18, 18]\n",
    "plt.rcParams['lines.linewidth'] = 2\n",
    "# plt.rcParams['lines.markersize'] = 3\n",
    "# plt.rcParams['lines.marker'] = 'x'\n",
    "plt.rcParams['scatter.marker'] = '.'\n",
    "\n",
    "# fg_color = 'white'\n",
    "# plt.rcParams['grid.color'] = 'gray'\n",
    "# plt.rcParams['text.color'] = fg_color\n",
    "# plt.rcParams['ytick.color'] = fg_color\n",
    "# plt.rcParams['xtick.color'] = fg_color\n",
    "# plt.rcParams['axes.labelcolor'] = fg_color\n",
    "# plt.rcParams['axes.edgecolor'] = fg_color\n",
    "\n",
    "# bg_color = \"#323a48\"\n",
    "# plt.rcParams['figure.facecolor'] = bg_color\n",
    "# plt.rcParams['axes.facecolor'] = bg_color\n",
    "# plt.rcParams['legend.facecolor'] = bg_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['teb' 'dwb' 'rpp_bad' 'rpp']\n"
     ]
    }
   ],
   "source": [
    "df_real = pd.read_csv(path.expanduser(\"~/ds/performance_modelling/output/test_local_planning/results.csv\"))\n",
    "with open(path.expanduser(\"~/ds/performance_modelling/output/test_local_planning/results_info.yaml\")) as results_real_info_file:\n",
    "    results_real_info = yaml.safe_load(results_real_info_file)\n",
    "df_real = df_real[(df_real.amcl_alpha_factor.notna()) & (df_real.robot_model=='turtlebot3_waffle_performance_modelling')]\n",
    "df = df_real\n",
    "\n",
    "for i in range(0, 4):\n",
    "    df[f'beta_{i+1}'] = df['odometry_error'].apply(lambda x: eval(x)[i])\n",
    "\n",
    "df.rename(inplace=True, columns={\n",
    "    'localization_update_absolute_translation_error_mean': 'absolute_translation_error',\n",
    "    'localization_update_absolute_rotation_error_mean': 'absolute_rotation_error',\n",
    "    'localization_update_normalized_relative_translation_error_mean': 'normalized_relative_translation_error',\n",
    "    'localization_update_normalized_relative_rotation_error_mean': 'normalized_relative_rotation_error',\n",
    "    'localization_update_rate_mean': 'localization_update_rate',\n",
    "})\n",
    "df.loc[df.robot_model == 'turtlebot3_waffle_performance_modelling', 'robot_model'] = 'turtle'\n",
    "df.loc[df.robot_model == 'hunter2', 'robot_model'] = 'hunter'\n",
    "df['session_id'] =  df['run_id'].apply(lambda x:  x.split('_')[1]+'_'+x.split('_')[2]+'_'+x.split('_')[3])\n",
    "df['run_number'] =  df['run_id'].apply(lambda x:  int(x.split('_')[5]))\n",
    "df.max_steering_angle_deg = df.max_steering_angle_deg.fillna(90)\n",
    "\n",
    "df.loc[(df.fixed_rpp != True) & (df.local_planner_node == 'rpp'), 'local_planner_node'] = 'rpp_bad'\n",
    "print(df.local_planner_node.unique())\n",
    "df = df[(df.max_steering_angle_deg == 90.) & (df.robot_model == 'turtle') & (df.global_planner_node == 'navfn') & (df.localization_node == 'amcl')].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# base_path = \"/home/enrico/ds/performance_modelling/output/test_local_planning/\"\n",
    "# out_dir = \"motions_plots/odom_gt_vel/\"\n",
    "# if not path.exists(out_dir):\n",
    "#     os.makedirs(out_dir)\n",
    "\n",
    "# run_indices = df.run_index.unique()\n",
    "# environment_names = df.environment_name.unique()\n",
    "# local_planners = df.local_planner_node.unique()\n",
    "\n",
    "# max_vel_x = 0.26\n",
    "# max_vel_theta = 1.0\n",
    "# num_points = 1000000\n",
    "# for environment_name in environment_names:\n",
    "#     for run_index in run_indices:\n",
    "# #         print()\n",
    "# #         print(environment_name, run_index)\n",
    "#         df_s = df[(df.environment_name == environment_name) & (df.run_index == run_index)].copy()\n",
    "#         for local_planner in local_planners:\n",
    "#             run_ids = df_s[df_s.local_planner_node == local_planner].run_id\n",
    "#             run_output_folders = list(map(lambda x: path.join(base_path, x), run_ids))\n",
    "#             for i, run_output_folder in enumerate(run_output_folders):\n",
    "#                 # check the run is valid from run events\n",
    "#                 run_events_file_path = path.join(run_output_folder, \"benchmark_data\", \"run_events.csv\")\n",
    "#                 run_events_df = pd.read_csv(run_events_file_path, engine='python', sep=', ')\n",
    "#                 navigation_start_events = run_events_df[run_events_df.event == 'navigation_goal_accepted']\n",
    "#                 navigation_succeeded_events = run_events_df[(run_events_df.event == 'navigation_succeeded')]\n",
    "#                 navigation_failed_events = run_events_df[(run_events_df.event == 'navigation_failed')]\n",
    "#                 if len(navigation_start_events) != 1 or len(navigation_succeeded_events) + len(navigation_failed_events) != 1:\n",
    "#                     continue\n",
    "                \n",
    "#                 # get the dataframes for ground truth poses\n",
    "#                 ground_truth_poses_file_path = path.join(run_output_folder, \"benchmark_data\", \"ground_truth_poses.csv\")\n",
    "#                 ground_truth_poses_df = pd.read_csv(ground_truth_poses_file_path)                \n",
    "#                 plt.scatter(ground_truth_poses_df.v_theta, ground_truth_poses_df.v_x, marker='.', s=1**2, label=local_planner if i == 0 else None, color=local_planner_color[local_planner], alpha=0.5)#, rasterized=True)\n",
    "        \n",
    "#         rect=patches.Rectangle((-max_vel_theta, -max_vel_x), 2*max_vel_theta, 2*max_vel_x, fill=False, color=\"black\", linewidth=1, alpha=0.5)\n",
    "#         plt.gca().add_patch(rect)\n",
    "        \n",
    "#         plt.xlabel('v_theta')\n",
    "#         plt.ylabel('v_x')\n",
    "#         plt.xlim([-2*max_vel_theta, 2*max_vel_theta])\n",
    "#         plt.ylim([-2*max_vel_x, 2*max_vel_x])\n",
    "#         plt.grid()\n",
    "#         plt.legend()\n",
    "#         plt.savefig(path.join(out_dir, f\"vel_theta_x_distribution_{environment_name}_{run_index}.png\"), bb_inches='tight')\n",
    "# #         plt.show()\n",
    "#         plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_path = \"/home/enrico/ds/performance_modelling/output/test_local_planning/\"\n",
    "out_dir = \"motions_plots/odom_gt_vel/\"\n",
    "if not path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "run_indices = df.run_index.unique()\n",
    "environment_names = df.environment_name.unique()\n",
    "local_planners = df.local_planner_node.unique()\n",
    "\n",
    "max_vel_x = 0.26\n",
    "max_vel_theta = 1.0\n",
    "num_points = 1000000\n",
    "for environment_name in environment_names:\n",
    "    for run_index in run_indices:\n",
    "#         print()\n",
    "#         print(environment_name, run_index)\n",
    "        df_s = df[(df.environment_name == environment_name) & (df.run_index == run_index)].copy()\n",
    "        for local_planner in local_planners:\n",
    "            run_ids = df_s[df_s.local_planner_node == local_planner].run_id\n",
    "            run_output_folders = list(map(lambda x: path.join(base_path, x), run_ids))\n",
    "            for i, run_output_folder in enumerate(run_output_folders):\n",
    "                # check the run is valid from run events\n",
    "                run_events_file_path = path.join(run_output_folder, \"benchmark_data\", \"run_events.csv\")\n",
    "                run_events_df = pd.read_csv(run_events_file_path, engine='python', sep=', ')\n",
    "                navigation_start_events = run_events_df[run_events_df.event == 'navigation_goal_accepted']\n",
    "                navigation_succeeded_events = run_events_df[(run_events_df.event == 'navigation_succeeded')]\n",
    "                navigation_failed_events = run_events_df[(run_events_df.event == 'navigation_failed')]\n",
    "                if len(navigation_start_events) != 1 or len(navigation_succeeded_events) + len(navigation_failed_events) != 1:\n",
    "                    continue\n",
    "                \n",
    "                # get the dataframes for ground truth poses\n",
    "                ground_truth_poses_file_path = path.join(run_output_folder, \"benchmark_data\", \"ground_truth_poses.csv\")\n",
    "                ground_truth_poses_df = pd.read_csv(ground_truth_poses_file_path)\n",
    "                \n",
    "#                 ground_truth_poses_df = ground_truth_poses_df.rolling(11, center=True).mean()\n",
    "                ground_truth_poses_df['v_tran'] = np.sqrt(ground_truth_poses_df.v_x**2 + ground_truth_poses_df.v_y**2)\n",
    "                ground_truth_poses_df['v_rot'] = ground_truth_poses_df.v_theta\n",
    "#                 diff_df = ground_truth_poses_df.diff()\n",
    "#                 diff_df['a_tran'] = np.sqrt((diff_df.v_x/diff_df.t)**2 + (diff_df.v_y/diff_df.t)**2)\n",
    "#                 diff_df['a_rot'] = diff_df.v_theta/diff_df.t\n",
    "#                 diff_df = diff_df.rolling(11, center=True).mean()\n",
    "                \n",
    "                plt.scatter(ground_truth_poses_df.v_rot, ground_truth_poses_df.v_tran, marker='.', s=1**2, label=local_planner if i == 0 else None, color=local_planner_color[local_planner], alpha=0.5)#, rasterized=True)\n",
    "        \n",
    "        rect=patches.Rectangle((-max_vel_theta, 0), 2*max_vel_theta, max_vel_x, fill=False, color=\"black\", linewidth=1, alpha=0.5)\n",
    "        plt.gca().add_patch(rect)\n",
    "        \n",
    "        plt.xlabel('v_rot')\n",
    "        plt.ylabel('v_tran')\n",
    "        plt.xlim([-2*max_vel_theta, 2*max_vel_theta])\n",
    "        plt.ylim([0, 2*max_vel_x])\n",
    "        plt.grid()\n",
    "        plt.legend()\n",
    "        plt.savefig(path.join(out_dir, f\"vel_rot_tran_distribution_{environment_name}_{run_index}.png\"), bb_inches='tight')\n",
    "#         plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_path = \"/home/enrico/ds/performance_modelling/output/test_local_planning/\"\n",
    "out_dir = \"motions_plots/odom_gt_acc_world/\"\n",
    "if not path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "run_indices = df.run_index.unique()\n",
    "environment_names = df.environment_name.unique()\n",
    "local_planners = df.local_planner_node.unique()\n",
    "\n",
    "max_acc_x = 2.5\n",
    "max_acc_theta = 3.2\n",
    "num_points = 1000000\n",
    "for environment_name in environment_names:\n",
    "    for run_index in run_indices:\n",
    "#         print()\n",
    "#         print(environment_name, run_index)\n",
    "        df_s = df[(df.environment_name == environment_name) & (df.run_index == run_index)].copy()\n",
    "        for local_planner in local_planners:\n",
    "            run_ids = df_s[df_s.local_planner_node == local_planner].run_id\n",
    "            run_output_folders = list(map(lambda x: path.join(base_path, x), run_ids))\n",
    "            for i, run_output_folder in enumerate(run_output_folders):\n",
    "                # check the run is valid from run events\n",
    "                run_events_file_path = path.join(run_output_folder, \"benchmark_data\", \"run_events.csv\")\n",
    "                run_events_df = pd.read_csv(run_events_file_path, engine='python', sep=', ')\n",
    "                navigation_start_events = run_events_df[run_events_df.event == 'navigation_goal_accepted']\n",
    "                navigation_succeeded_events = run_events_df[(run_events_df.event == 'navigation_succeeded')]\n",
    "                navigation_failed_events = run_events_df[(run_events_df.event == 'navigation_failed')]\n",
    "                if len(navigation_start_events) != 1 or len(navigation_succeeded_events) + len(navigation_failed_events) != 1:\n",
    "                    continue\n",
    "                \n",
    "                # get the dataframes for ground truth poses\n",
    "                ground_truth_poses_file_path = path.join(run_output_folder, \"benchmark_data\", \"ground_truth_poses.csv\")\n",
    "                ground_truth_poses_df = pd.read_csv(ground_truth_poses_file_path)\n",
    "                \n",
    "#                 ground_truth_poses_df = ground_truth_poses_df.rolling(11, center=True).mean()\n",
    "                ground_truth_poses_df['v_tran'] = np.sqrt(ground_truth_poses_df.v_x**2 + ground_truth_poses_df.v_y**2)\n",
    "                ground_truth_poses_df['v_rot'] = ground_truth_poses_df.v_theta\n",
    "                diff_df = ground_truth_poses_df.diff()\n",
    "                diff_df['a_tran'] = np.sqrt((diff_df.v_x/diff_df.t)**2 + (diff_df.v_y/diff_df.t)**2)\n",
    "                diff_df['a_rot'] = diff_df.v_theta/diff_df.t\n",
    "                diff_df = diff_df.rolling(11, center=True).mean()\n",
    "                \n",
    "                plt.scatter(diff_df.a_rot, diff_df.a_tran, marker='.', s=1**2, label=local_planner if i == 0 else None, color=local_planner_color[local_planner], alpha=0.5)#, rasterized=True)\n",
    "        \n",
    "        rect=patches.Rectangle((-max_acc_theta, 0), 2*max_acc_theta, max_acc_x, fill=False, color=\"black\", linewidth=1, alpha=0.5)\n",
    "        plt.gca().add_patch(rect)\n",
    "        \n",
    "        plt.xlabel('a_rot')\n",
    "        plt.ylabel('a_tran')\n",
    "        plt.xlim([-2*max_acc_theta, 2*max_acc_theta])\n",
    "        plt.ylim([0, 2*max_acc_x])\n",
    "        plt.grid()\n",
    "        plt.legend()\n",
    "        plt.savefig(path.join(out_dir, f\"acc_rot_tran_distribution_{environment_name}_{run_index}.png\"), bb_inches='tight')\n",
    "#         plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/home/enrico/ds/performance_modelling/output/test_local_planning/\"\n",
    "out_dir = \"motions_plots/cmd_vel/\"\n",
    "if not path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "run_indices = df.run_index.unique()\n",
    "environment_names = df.environment_name.unique()\n",
    "local_planners = df.local_planner_node.unique()\n",
    "\n",
    "max_vel_x = 0.26\n",
    "max_vel_theta = 1.0\n",
    "for environment_name in environment_names:\n",
    "    for run_index in run_indices:\n",
    "        df_s = df[(df.environment_name == environment_name) & (df.run_index == run_index)].copy()\n",
    "        for local_planner in local_planners:\n",
    "            run_ids = df_s[df_s.local_planner_node == local_planner].run_id\n",
    "            run_output_folders = list(map(lambda x: path.join(base_path, x), run_ids))\n",
    "            for i, run_output_folder in enumerate(run_output_folders):\n",
    "                # check the run is valid from run events\n",
    "                run_events_file_path = path.join(run_output_folder, \"benchmark_data\", \"run_events.csv\")\n",
    "                run_events_df = pd.read_csv(run_events_file_path, engine='python', sep=', ')\n",
    "                navigation_start_events = run_events_df[run_events_df.event == 'navigation_goal_accepted']\n",
    "                navigation_succeeded_events = run_events_df[(run_events_df.event == 'navigation_succeeded')]\n",
    "                navigation_failed_events = run_events_df[(run_events_df.event == 'navigation_failed')]\n",
    "                if len(navigation_start_events) != 1 or len(navigation_succeeded_events) + len(navigation_failed_events) != 1:\n",
    "                    continue\n",
    "\n",
    "                # get the dataframes for velocity commands\n",
    "                cmd_vel_file_path = path.join(run_output_folder, \"benchmark_data\", \"cmd_vel.csv\")\n",
    "                cmd_vel_df = pd.read_csv(cmd_vel_file_path)\n",
    "                plt.scatter(cmd_vel_df.angular_z, cmd_vel_df.linear_x, marker='.', s=1**2, label=local_planner if i == 0 else None, color=local_planner_color[local_planner], alpha=0.5)#, rasterized=True)\n",
    "        \n",
    "        rect=patches.Rectangle((-max_vel_theta, -max_vel_x), 2*max_vel_theta, 2*max_vel_x, fill=False, color=\"black\", linewidth=1, alpha=0.5)\n",
    "        plt.gca().add_patch(rect)\n",
    "        \n",
    "        plt.xlabel('angular_z')\n",
    "        plt.ylabel('linear_x')\n",
    "        plt.xlim([-2*max_vel_theta, 2*max_vel_theta])\n",
    "        plt.ylim([-2*max_vel_x, 2*max_vel_x])\n",
    "        plt.grid()\n",
    "        plt.legend()\n",
    "        plt.savefig(path.join(out_dir, f\"vel_theta_x_distribution_{environment_name}_{run_index}.png\"), bb_inches='tight')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/home/enrico/ds/performance_modelling/output/test_local_planning/\"\n",
    "out_dir = \"motions_plots/trajectory/\"\n",
    "if not path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "run_indices = df.run_index.unique()\n",
    "environment_names = df.environment_name.unique()\n",
    "local_planners = df.local_planner_node.unique()\n",
    "\n",
    "for environment_name in environment_names:\n",
    "    for run_index in run_indices:\n",
    "        df_s = df[(df.environment_name == environment_name) & (df.run_index == run_index)].copy()\n",
    "        for local_planner in local_planners:\n",
    "            run_ids = df_s[df_s.local_planner_node == local_planner].run_id\n",
    "            run_output_folders = list(map(lambda x: path.join(base_path, x), run_ids))\n",
    "            for i, run_output_folder in enumerate(run_output_folders):\n",
    "                # check the run is valid from run events\n",
    "                run_events_file_path = path.join(run_output_folder, \"benchmark_data\", \"run_events.csv\")\n",
    "                run_events_df = pd.read_csv(run_events_file_path, engine='python', sep=', ')\n",
    "                navigation_start_events = run_events_df[run_events_df.event == 'navigation_goal_accepted']\n",
    "                navigation_succeeded_events = run_events_df[(run_events_df.event == 'navigation_succeeded')]\n",
    "                navigation_failed_events = run_events_df[(run_events_df.event == 'navigation_failed')]\n",
    "                if len(navigation_start_events) != 1 or len(navigation_succeeded_events) + len(navigation_failed_events) != 1:\n",
    "                    continue\n",
    "\n",
    "                # get the dataframes for ground truth poses\n",
    "                ground_truth_poses_file_path = path.join(run_output_folder, \"benchmark_data\", \"ground_truth_poses.csv\")\n",
    "                ground_truth_poses_df = pd.read_csv(ground_truth_poses_file_path)\n",
    "                plt.scatter(ground_truth_poses_df.x, ground_truth_poses_df.y, marker='.', s=1**2, label=local_planner if i == 0 else None, color=local_planner_color[local_planner], alpha=0.5)#, rasterized=True)\n",
    "        \n",
    "        plt.xlabel('x')\n",
    "        plt.ylabel('y')\n",
    "        plt.gca().set_aspect('equal', adjustable='box')\n",
    "        plt.grid()\n",
    "        plt.legend()\n",
    "        plt.savefig(path.join(out_dir, f\"trajectory_{environment_name}_{run_index}.png\"), bb_inches='tight')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# base_path = \"/home/enrico/ds/performance_modelling/output/test_local_planning/\"\n",
    "# out_dir = \"motions_plots/trajectory_single_runs/\"\n",
    "# if not path.exists(out_dir):\n",
    "#     os.makedirs(out_dir)\n",
    "\n",
    "# run_indices = df.run_index.unique()\n",
    "# environment_names = df.environment_name.unique()\n",
    "# local_planners = df.local_planner_node.unique()\n",
    "\n",
    "# for environment_name in environment_names:\n",
    "#     for run_index in run_indices:\n",
    "#         df_s = df[(df.environment_name == environment_name) & (df.run_index == run_index)].copy()\n",
    "#         for local_planner in local_planners:\n",
    "#             run_ids = df_s[df_s.local_planner_node == local_planner].run_id\n",
    "#             run_output_folders = list(map(lambda x: path.join(base_path, x), run_ids))\n",
    "#             for i, (run_id, run_output_folder) in enumerate(zip(run_ids, run_output_folders)):\n",
    "#                 # check the run is valid from run events\n",
    "#                 run_events_file_path = path.join(run_output_folder, \"benchmark_data\", \"run_events.csv\")\n",
    "#                 run_events_df = pd.read_csv(run_events_file_path, engine='python', sep=', ')\n",
    "#                 navigation_start_events = run_events_df[run_events_df.event == 'navigation_goal_accepted']\n",
    "#                 navigation_succeeded_events = run_events_df[(run_events_df.event == 'navigation_succeeded')]\n",
    "#                 navigation_failed_events = run_events_df[(run_events_df.event == 'navigation_failed')]\n",
    "#                 if len(navigation_start_events) != 1 or len(navigation_succeeded_events) + len(navigation_failed_events) != 1:\n",
    "#                     continue\n",
    "\n",
    "#                 for o_local_planner in local_planners:\n",
    "#                     o_run_ids = df_s[df_s.local_planner_node == o_local_planner].run_id\n",
    "#                     o_run_output_folders = list(map(lambda x: path.join(base_path, x), o_run_ids))\n",
    "#                     for o_i, o_run_output_folder in enumerate(o_run_output_folders):\n",
    "#                         # get the dataframes for ground truth poses\n",
    "#                         o_ground_truth_poses_file_path = path.join(o_run_output_folder, \"benchmark_data\", \"ground_truth_poses.csv\")\n",
    "#                         o_ground_truth_poses_df = pd.read_csv(o_ground_truth_poses_file_path)\n",
    "#                         plt.scatter(o_ground_truth_poses_df.x, o_ground_truth_poses_df.y, marker='.', s=1**2, color='lightgray')\n",
    "\n",
    "#                 # get the dataframes for ground truth poses\n",
    "#                 ground_truth_poses_file_path = path.join(run_output_folder, \"benchmark_data\", \"ground_truth_poses.csv\")\n",
    "#                 ground_truth_poses_df = pd.read_csv(ground_truth_poses_file_path)\n",
    "                \n",
    "#                 try:\n",
    "#                     beta_1 = df_s[df_s.run_id == run_id].beta_1.iloc[0]\n",
    "#                 except:\n",
    "#                     beta_1 = \"NaN\"\n",
    "                \n",
    "#                 plt.scatter(ground_truth_poses_df.x, ground_truth_poses_df.y, marker='.', s=1**2, label=f\"{local_planner}, beta: {beta_1}\", color=local_planner_color[local_planner], alpha=0.5)\n",
    "\n",
    "#                 plt.xlabel('x')\n",
    "#                 plt.ylabel('y')\n",
    "#                 plt.gca().set_aspect('equal')\n",
    "#                 plt.grid()\n",
    "#                 plt.legend()\n",
    "#                 plt.savefig(path.join(out_dir, f\"trajectory_{environment_name}_{run_index}_run_{run_id}.png\"), bb_inches='tight')\n",
    "#                 plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

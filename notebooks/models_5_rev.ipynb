{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import Markdown, display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "\n",
    "from collections import defaultdict\n",
    "import traceback\n",
    "import numpy as np\n",
    "import scipy.stats as ss\n",
    "import random\n",
    "import copy\n",
    "import yaml\n",
    "import itertools\n",
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "from os import path\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "np.set_printoptions(edgeitems=30, linewidth=1000)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, TheilSenRegressor, RANSACRegressor, HuberRegressor, LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "def printmd(*args):\n",
    "    display(Markdown(' '.join(map(str, args))))\n",
    "\n",
    "def print_warn(*args):\n",
    "    printmd(f\"<code><font style='background-color:yellow;font-family:monospace'>{' '.join(map(str, args))}</font></code>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !ros2 run local_planning_performance_modelling compute_metrics -r \"~/ds/performance_modelling/output/test_local_planning/*\" -s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !ros2 run local_planning_performance_modelling compute_metrics -r \"~/ds/performance_modelling/output/test_local_planning_gen_circles/*\" -s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "local_planner_color = {'dwb': 'blue', 'rpp': 'orange', 'teb': 'green'}\n",
    "robot_model_color = {'hunter': 'cyan', 'turtle': 'green'}\n",
    "pd.options.display.width = 500\n",
    "pd.options.display.max_rows = 0\n",
    "pd.options.display.float_format = '{:,.3f}'.format\n",
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "plt.rcParams['lines.linewidth'] = 2\n",
    "# plt.rcParams['lines.markersize'] = 3\n",
    "# plt.rcParams['lines.marker'] = 'o'\n",
    "\n",
    "# fg_color = 'white'\n",
    "# plt.rcParams['grid.color'] = 'gray'\n",
    "# plt.rcParams['text.color'] = fg_color\n",
    "# plt.rcParams['ytick.color'] = fg_color\n",
    "# plt.rcParams['xtick.color'] = fg_color\n",
    "# plt.rcParams['axes.labelcolor'] = fg_color\n",
    "# plt.rcParams['axes.edgecolor'] = fg_color\n",
    "\n",
    "# bg_color = \"#323a48\"\n",
    "# plt.rcParams['figure.facecolor'] = bg_color\n",
    "# plt.rcParams['axes.facecolor'] = bg_color\n",
    "# plt.rcParams['legend.facecolor'] = bg_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(path.expanduser(\"~/ds/performance_modelling/output/test_local_planning/results.csv\"))\n",
    "with open(path.expanduser(\"~/ds/performance_modelling/output/test_local_planning/results_info.yaml\")) as results_info_file:\n",
    "    results_info = yaml.safe_load(results_info_file)\n",
    "\n",
    "# df_real = pd.read_csv(path.expanduser(\"~/ds/performance_modelling/output/test_local_planning/results.csv\"))\n",
    "# with open(path.expanduser(\"~/ds/performance_modelling/output/test_local_planning/results_info.yaml\")) as results_real_info_file:\n",
    "#     results_real_info = yaml.safe_load(results_real_info_file)\n",
    "# df_real = df_real[(df_real.amcl_alpha_factor.notna()) & (df_real.robot_model=='turtlebot3_waffle_performance_modelling')]\n",
    "# \n",
    "# df_gen = pd.read_csv(path.expanduser(\"~/ds/performance_modelling/output/test_local_planning_gen_circles/results.csv\"))\n",
    "# with open(path.expanduser(\"~/ds/performance_modelling/output/test_local_planning_gen_circles/results_info.yaml\")) as results_gen_info_file:\n",
    "#     results_gen_info = yaml.safe_load(results_gen_info_file)\n",
    "\n",
    "# df = df_gen.append(df_real, sort=True)\n",
    "\n",
    "df.rename(inplace=True, columns={\n",
    "    'collisionless_localization_update_absolute_translation_error_mean': 'absolute_translation_error',\n",
    "    'collisionless_localization_update_absolute_rotation_error_mean': 'absolute_rotation_error',\n",
    "    'collisionless_localization_update_normalized_relative_translation_error_mean': 'normalized_relative_translation_error',\n",
    "    'collisionless_localization_update_normalized_relative_rotation_error_mean': 'normalized_relative_rotation_error',\n",
    "    'localization_update_rate_mean': 'localization_update_rate',\n",
    "})\n",
    "\n",
    "# results_info = results_gen_info\n",
    "# results_info['run_parameter_names'] += [i for i in results_real_info['run_parameter_names'] if i not in results_info['run_parameter_names']]\n",
    "\n",
    "# TEMP: only consider real localization\n",
    "# df = df[df.localization_node != 'localization_generator']\n",
    "# df = df[(df.amcl_alpha_factor == 1.0) | (df.amcl_alpha_factor == 0.0)]\n",
    "\n",
    "df.fixed_rpp = df.fixed_rpp.fillna(False)\n",
    "df.loc[(df.fixed_rpp == False) & (df.local_planner_node == 'rpp'), 'local_planner_node'] = 'rpp_bad'\n",
    "df = df[df.local_planner_node != 'rpp_bad'].copy()\n",
    "\n",
    "# df = df[df.amcl_alpha_factor.notna()]\n",
    "\n",
    "# turn odometry_error into beta_1..4\n",
    "results_info['run_parameter_names'] += ['beta_1', 'beta_2', 'beta_3', 'beta_4']\n",
    "results_info['run_parameter_names'].remove('odometry_error')\n",
    "for i in range(0, 4):\n",
    "    df[f'beta_{i+1}'] = df['odometry_error'].apply(lambda x: eval(x)[i])\n",
    "del df['odometry_error']\n",
    "\n",
    "df.loc[df.robot_model == 'turtlebot3_waffle_performance_modelling', 'robot_model'] = 'turtle'\n",
    "df.loc[df.robot_model == 'hunter2', 'robot_model'] = 'hunter'\n",
    "\n",
    "run_parameters = [c for c in list(df.columns) if c in results_info['run_parameter_names']]\n",
    "metrics_versions = [c for c in list(df.columns) if '_version' in c]\n",
    "everything_else = ['run_id', 'session_id', 'run_number']\n",
    "metrics = [c for c in df.columns if c not in metrics_versions + run_parameters + everything_else]\n",
    "metrics_and_versions = [c for c in list(df.columns) if '_version' in c or c in metrics]\n",
    "\n",
    "cpu_time_metrics = [c for c in metrics if 'cpu_time' in c]\n",
    "max_memory_metrics = [c for c in metrics if 'max_memory' in c]\n",
    "\n",
    "# add useful parameters\n",
    "df['session_id'] =  df['run_id'].apply(lambda x:  x.split('_')[1]+'_'+x.split('_')[2]+'_'+x.split('_')[3])\n",
    "df['run_number'] =  df['run_id'].apply(lambda x:  int(x.split('_')[5]))\n",
    "df[max_memory_metrics] = df[max_memory_metrics]/1024**2\n",
    "df.max_steering_angle_deg = df.max_steering_angle_deg.fillna(90)\n",
    "\n",
    "# add metrics from existing ones\n",
    "df['average_velocity'] = df['trajectory_length'] / df['execution_time']\n",
    "df['collisionless_success_rate'] = df['success_rate'] & (1 - df['collision_rate'])\n",
    "metrics += ['average_velocity', 'collisionless_success_rate']\n",
    "metrics_and_versions += ['average_velocity', 'collisionless_success_rate']\n",
    "\n",
    "# add aggregated data\n",
    "min_trajectory_length_group_df = df.groupby([\"environment_name\", \"run_index\", \"collisionless_success_rate\"])\n",
    "for (environment_name, run_index, collisionless_success_rate), group_df in min_trajectory_length_group_df:\n",
    "    df.loc[(df.environment_name == environment_name) & (df.run_index == run_index) & (collisionless_success_rate), 'min_trajectory_length'] = group_df.trajectory_length.min()\n",
    "df['norm_trajectory_length'] = df.trajectory_length / df.min_trajectory_length\n",
    "metrics += ['norm_trajectory_length']\n",
    "metrics_and_versions += ['norm_trajectory_length']\n",
    "\n",
    "min_execution_time_group_df = df.groupby([\"environment_name\", \"run_index\", \"collisionless_success_rate\"])\n",
    "for (environment_name, run_index, collisionless_success_rate), group_df in min_execution_time_group_df:\n",
    "    df.loc[(df.environment_name == environment_name) & (df.run_index == run_index) & (collisionless_success_rate), 'min_execution_time'] = group_df.execution_time.min()\n",
    "df['norm_execution_time'] = df.execution_time / df.min_execution_time\n",
    "metrics += ['norm_execution_time']\n",
    "metrics_and_versions += ['norm_execution_time']\n",
    "\n",
    "if False:\n",
    "# if True:\n",
    "    printmd(\"## Number of Runs\")\n",
    "    printmd(f\"    {len(df.run_id.unique())}\")\n",
    "\n",
    "    printmd(\"## Run Parameters\")\n",
    "    for name in [run_parameter_name for run_parameter_name in run_parameters if 'localization_generator_' not in run_parameter_name]:\n",
    "        values = list(df[name].unique())\n",
    "        printmd(f\"    {name:<70}\", sorted(values))\n",
    "\n",
    "    printmd(\"## Metrics\")\n",
    "    for name in metrics_and_versions:\n",
    "        if name in metrics_versions:\n",
    "            if len(df[name].unique()) == 1:\n",
    "                printmd(f\"    {name:<70} {sorted(df[name].unique())}\")\n",
    "            else:\n",
    "                printmd(f\"<code><font style='background-color:yellow;font-family:monospace'>{name:<70}{sorted(df[name].unique())} </font></code> ⚠️\")\n",
    "        else:\n",
    "            printmd(f\"    {name:<70} min: {df[name].min(skipna=True):10.4g} {'avg':>15}: {df[name].mean(skipna=True):10.4g} {'max':>15}: {df[name].max(skipna=True):10.4g} {'nan':>15}: {sum(df[name].isna()):10.4g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset splits based on run_index\n",
    "ri = sorted(df.run_index.unique())\n",
    "random.Random(0).shuffle(ri)\n",
    "l = len(ri)\n",
    "split_localization, split_local_planner, split_ground_truth = ri[0:int(l/3)], ri[int(l/3):int(2*l/3)], ri[int(2*l/3):]\n",
    "len(split_localization), len(split_local_planner), len(split_ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# discretize features\n",
    "bin_widths_dict = {\n",
    "    'amcl_alpha_factor': (None, None),\n",
    "    'beta_1': (None, None),\n",
    "    'absolute_translation_error': (0.0, 0.06),\n",
    "    'absolute_rotation_error': (0.0, 0.03),\n",
    "    'normalized_relative_translation_error': (0.0, 0.03),\n",
    "    'normalized_relative_rotation_error': (0.0, 0.015),\n",
    "    'collisionless_success_rate': (-0.5, 1),\n",
    "    'collision_rate': (-0.5, 1),\n",
    "    'norm_trajectory_length': (1.0, 0.015),\n",
    "    'norm_execution_time': (1.0, 0.015),\n",
    "    'average_translation_velocity': (0.0, 0.015),\n",
    "    'average_velocity_atan': (0.0, 0.15),\n",
    "}\n",
    "# bin_widths_dict = {\n",
    "#     'amcl_alpha_factor': (None, None),\n",
    "#     'beta_1': (None, None),\n",
    "#     'absolute_translation_error': (0.0, 0.03),\n",
    "#     'absolute_rotation_error': (0.0, 0.003),\n",
    "#     'normalized_relative_translation_error': (0.0, 0.015),\n",
    "#     'normalized_relative_rotation_error': (0.0, 0.015),\n",
    "#     'collisionless_success_rate': (-0.5, 1),\n",
    "#     'collision_rate': (-0.5, 1),\n",
    "#     'norm_trajectory_length': (1.0, 0.015),\n",
    "#     'norm_execution_time': (1.0, 0.015),\n",
    "#     'average_translation_velocity': (0.0, 0.015),\n",
    "#     'average_velocity_atan': (0.0, 0.15),\n",
    "# }\n",
    "\n",
    "bins_dict = dict()\n",
    "for feature_name, (bin_min, bin_width) in bin_widths_dict.items():\n",
    "    if bin_width is not None:\n",
    "        bins = np.arange(bin_min, df[feature_name].max() + bin_width, bin_width)\n",
    "        bins_dict[feature_name] = bins[:-1]\n",
    "        df[f'{feature_name}_d'] = pd.cut(df[feature_name], bins, right=False, labels=bins[:-1]).astype('float')\n",
    "    else:\n",
    "        df[f'{feature_name}_d'] = df[feature_name]\n",
    "        bins_dict[feature_name] = sorted(df[feature_name].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "local_planner_performance_all = [\n",
    "    'collisionless_success_rate',\n",
    "    'collision_rate',\n",
    "]\n",
    "local_planner_performance_success = [\n",
    "    'norm_trajectory_length',\n",
    "    'norm_execution_time',\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-9-ce796b8ecb48>, line 34)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-ce796b8ecb48>\"\u001b[0;36m, line \u001b[0;32m34\u001b[0m\n\u001b[0;31m    dl = d_localization\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "def compute_joint_cr(amcl_alpha_factor, beta_1, smoothing_value):\n",
    "    \n",
    "    localization_performance = [\n",
    "        'absolute_translation_error',\n",
    "        'absolute_rotation_error',\n",
    "        'normalized_relative_translation_error',\n",
    "    #     'normalized_relative_rotation_error',\n",
    "    ]\n",
    "    \n",
    "    d_all = df[\n",
    "        (df.max_steering_angle_deg == 90.) &\n",
    "        (df.robot_model == 'turtle') &\n",
    "        (df.global_planner_node == 'navfn') &\n",
    "        (df.localization_node == 'amcl')  &\n",
    "        (df.local_planner_node == 'dwb') &\n",
    "        (df.amcl_alpha_factor == amcl_alpha_factor) &\n",
    "        (df.beta_1 == beta_1)].copy()\n",
    "#     d_success = df[\n",
    "#         (df.collisionless_success_rate == 1) &\n",
    "#         (df.max_steering_angle_deg == 90.) &\n",
    "#         (df.robot_model == 'turtle') &\n",
    "#         (df.global_planner_node == 'navfn') &\n",
    "#         (df.localization_node == 'amcl') &\n",
    "#         (df.local_planner_node == 'teb') &\n",
    "#         (df.amcl_alpha_factor == amcl_alpha_factor) &\n",
    "#         (df.beta_1 == beta_1)].copy()\n",
    "\n",
    "    d_localization = d_all[d_all.run_index.isin(split_localization)]\n",
    "    d_local_planner_all = d_all[d_all.run_index.isin(split_local_planner)]\n",
    "#     d_local_planner_success = d_success[d_success.run_index.isin(split_local_planner)]\n",
    "    d_gt_all = d_all[d_all.run_index.isin(split_ground_truth)]\n",
    "#     d_gt_success = d_success[d_success.run_index.isin(split_ground_truth)]\n",
    "b\n",
    "    dl = d_localization\n",
    "    joint_count = dl.groupby(localization_performance)[localization_performance].count()\n",
    "    itertools.product()\n",
    "\n",
    "    loc_bins = [bins_dict[x] for x in bins_dict.keys() if x in localization_performance]\n",
    "    loc_space_comb = list(itertools.product(*loc_bins))\n",
    "    localization_performance_len = tuple(map(len, loc_bins))\n",
    "#     print(\"localization_performance_len\", localization_performance_len)\n",
    "    p = np.zeros(localization_performance_len)\n",
    "    count = np.zeros(localization_performance_len)\n",
    "    for (i, j, k), (x_ate, x_are, x_nrte) in zip(np.ndindex(*localization_performance_len), loc_space_comb):\n",
    "#         print(f\"ate_i={i}, are_i={j}, x_ate={x_ate}, x_are={x_are}, x_nrte={x_nrte}, \")\n",
    "#         print(dl[(dl.absolute_translation_error_d == x_ate) & (dl.absolute_rotation_error_d == x_are) & (dl.normalized_relative_translation_error_d == x_nrte)][localization_performance])\n",
    "        count[i, j, k] = dl[(dl.absolute_translation_error_d == x_ate) & (dl.absolute_rotation_error_d == x_are) & (dl.normalized_relative_translation_error_d == x_nrte)][localization_performance[0]].count()\n",
    "    #     print(count[i, j])\n",
    "\n",
    "    p = (count / count.sum()) + np.ones(localization_performance_len) * smoothing_value\n",
    "#     print(p)\n",
    "    p = p / p.sum()\n",
    "#     print(p)\n",
    "\n",
    "    # print(localization_performance)\n",
    "    # print(localization_performance_len)\n",
    "\n",
    "    # print(\"p\")\n",
    "    # print(p)\n",
    "    # print(\"ate marginal\", p.sum(axis=1))\n",
    "    # print(\"are marginal\", p.sum(axis=0))\n",
    "\n",
    "    dlp = d_local_planner_all\n",
    "\n",
    "    p_cr_0 = 0.0\n",
    "    for (i, j, k), (x_ate, x_are, x_nrte) in zip(np.ndindex(*localization_performance_len), loc_space_comb):\n",
    "        count_ij = dlp[(dlp.collision_rate_d == -0.5) & (dlp.absolute_translation_error_d == x_ate) & (dlp.absolute_rotation_error_d == x_are) & (dlp.normalized_relative_translation_error_d == x_nrte)]['collision_rate_d'].count()\n",
    "        total_ij = dlp[(dlp.absolute_translation_error_d == x_ate) & (dlp.absolute_rotation_error_d == x_are) & (dlp.normalized_relative_translation_error_d == x_nrte)]['collision_rate_d'].count()\n",
    "        p_cr_0 += p[i, j, k] * (count_ij / total_ij) if total_ij > 0 else 0\n",
    "    \n",
    "    p_cr_1 = 0.0\n",
    "    for (i, j, k), (x_ate, x_are, x_nrte) in zip(np.ndindex(*localization_performance_len), loc_space_comb):\n",
    "        count_ij = dlp[(dlp.collision_rate_d == 0.5) & (dlp.absolute_translation_error_d == x_ate) & (dlp.absolute_rotation_error_d == x_are) & (dlp.normalized_relative_translation_error_d == x_nrte)]['collision_rate_d'].count()\n",
    "        total_ij = dlp[(dlp.absolute_translation_error_d == x_ate) & (dlp.absolute_rotation_error_d == x_are) & (dlp.normalized_relative_translation_error_d == x_nrte)]['collision_rate_d'].count()\n",
    "        p_cr_1 += p[i, j, k] * (count_ij / total_ij) if total_ij > 0 else 0\n",
    "    \n",
    "#     print(\"p_cr_0 + p_cr_1\", p_cr_0 + p_cr_1)\n",
    "    p_cr_1 = p_cr_1 / (p_cr_0 + p_cr_1)\n",
    "    \n",
    "    p_cr_1_gt = d_gt_all['collision_rate'].mean()\n",
    "    \n",
    "    return p_cr_1, p_cr_1_gt\n",
    "\n",
    "# amcl_alpha_factor_values = [1.0]\n",
    "amcl_alpha_factor_values = [0.5, 1.0, 2.0]\n",
    "beta_1_values = [0.02, 0.05, 0.1]\n",
    "# for smoothing_value in np.linspace(0.0001, 0.01, 100):\n",
    "for smoothing_value in [0.0]:\n",
    "    for amcl_alpha_factor in amcl_alpha_factor_values:\n",
    "        fig = plt.figure()\n",
    "        beta_1_y_p_cr_1 = list()\n",
    "        beta_1_y_data = list()\n",
    "        for beta_1 in beta_1_values:\n",
    "            p_cr_1, p_cr_1_gt = compute_joint_cr(amcl_alpha_factor, beta_1, smoothing_value=smoothing_value)\n",
    "            beta_1_y_p_cr_1.append(p_cr_1)\n",
    "            beta_1_y_data.append(p_cr_1_gt)\n",
    "        plt.plot(beta_1_values, beta_1_y_p_cr_1, '.-', label=f\"p_cr_1, amcl_alpha_factor={amcl_alpha_factor}\")\n",
    "        plt.plot(beta_1_values, beta_1_y_data, '.--', label=f\"data, amcl_alpha_factor={amcl_alpha_factor}\")\n",
    "\n",
    "        plt.grid()\n",
    "        plt.legend(bbox_to_anchor=(1.04, 1), borderaxespad=0)\n",
    "        plt.xlabel(\"beta_1\")\n",
    "        plt.ylabel(f\"{'collision_rate'.replace('_', ' ')} from joint dist (x_ate, x_are, x_nrte)\")\n",
    "        plt.ylim([0, 1])\n",
    "        fig.set_size_inches([3, 3])\n",
    "#         plt.savefig(f\"plots/smoothing/ate_are_nrte___amcl_{int(amcl_alpha_factor*10)}_smoothing_{int(smoothing_value*1000000)}.png\")\n",
    "#         plt.close()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def compute_joint_cr(amcl_alpha_factor, beta_1, smoothing_value):\n",
    "    \n",
    "    localization_performance = [\n",
    "        'absolute_translation_error',\n",
    "#         'absolute_rotation_error',\n",
    "        'normalized_relative_translation_error',\n",
    "    #     'normalized_relative_rotation_error',\n",
    "    ]\n",
    "    d_all = df[\n",
    "        (df.max_steering_angle_deg == 90.) &\n",
    "        (df.robot_model == 'turtle') &\n",
    "        (df.global_planner_node == 'navfn') &\n",
    "        (df.localization_node == 'amcl')  &\n",
    "        (df.local_planner_node == 'teb') &\n",
    "        (df.amcl_alpha_factor == amcl_alpha_factor) &\n",
    "        (df.beta_1 == beta_1)].copy()\n",
    "#     d_success = df[\n",
    "#         (df.collisionless_success_rate == 1) &\n",
    "#         (df.max_steering_angle_deg == 90.) &\n",
    "#         (df.robot_model == 'turtle') &\n",
    "#         (df.global_planner_node == 'navfn') &\n",
    "#         (df.localization_node == 'amcl') &\n",
    "#         (df.local_planner_node == 'teb') &\n",
    "#         (df.amcl_alpha_factor == amcl_alpha_factor) &\n",
    "#         (df.beta_1 == beta_1)].copy()\n",
    "\n",
    "    d_localization = d_all[d_all.run_index.isin(split_localization)]\n",
    "    d_local_planner_all = d_all[d_all.run_index.isin(split_local_planner)]\n",
    "#     d_local_planner_success = d_success[d_success.run_index.isin(split_local_planner)]\n",
    "    d_gt_all = d_all[d_all.run_index.isin(split_ground_truth)]\n",
    "#     d_gt_success = d_success[d_success.run_index.isin(split_ground_truth)]\n",
    "\n",
    "    dl = d_localization\n",
    "    joint_count = dl.groupby(localization_performance)[localization_performance].count()\n",
    "    itertools.product()\n",
    "\n",
    "    loc_bins = [bins_dict[x] for x in bins_dict.keys() if x in localization_performance]\n",
    "    loc_space_comb = list(itertools.product(*loc_bins))\n",
    "    localization_performance_len = tuple(map(len, loc_bins))\n",
    "#     print(\"localization_performance_len\", localization_performance_len)\n",
    "    p = np.zeros(localization_performance_len)\n",
    "    count = np.zeros(localization_performance_len)\n",
    "    for (i, j), (x_ate, x_nrte) in zip(np.ndindex(*localization_performance_len), loc_space_comb):\n",
    "#         print(f\"ate_i={i}, are_i={j}, x_ate={x_ate}, x_are={x_are}, x_nrte={x_nrte}, \")\n",
    "#         print(dl[(dl.absolute_translation_error_d == x_ate) & (dl.absolute_rotation_error_d == x_are) & (dl.normalized_relative_translation_error_d == x_nrte)][localization_performance])\n",
    "        count[i, j] = dl[(dl.absolute_translation_error_d == x_ate) & (dl.normalized_relative_translation_error_d == x_nrte)][localization_performance[0]].count()\n",
    "    #     print(count[i, j])\n",
    "\n",
    "    p = (count / count.sum()) + np.ones(localization_performance_len) * smoothing_value\n",
    "#     print(p)\n",
    "    p = p / p.sum()\n",
    "#     print(p)\n",
    "\n",
    "    # print(localization_performance)\n",
    "    # print(localization_performance_len)\n",
    "\n",
    "    # print(\"p\")\n",
    "    # print(p)\n",
    "    # print(\"ate marginal\", p.sum(axis=1))\n",
    "    # print(\"are marginal\", p.sum(axis=0))\n",
    "\n",
    "    dlp = d_local_planner_all\n",
    "\n",
    "    p_cr_0 = 0.0\n",
    "    for (i, j), (x_ate, x_nrte) in zip(np.ndindex(*localization_performance_len), loc_space_comb):\n",
    "        count_ij = dlp[(dlp.collision_rate_d == -0.5) & (dlp.absolute_translation_error_d == x_ate) & (dlp.normalized_relative_translation_error_d == x_nrte)]['collision_rate_d'].count()\n",
    "        total_ij = dlp[(dlp.absolute_translation_error_d == x_ate) & (dlp.normalized_relative_translation_error_d == x_nrte)]['collision_rate_d'].count()\n",
    "        p_cr_0 += p[i, j] * (count_ij / total_ij) if total_ij > 0 else 0\n",
    "    \n",
    "    p_cr_1 = 0.0\n",
    "    for (i, j), (x_ate, x_nrte) in zip(np.ndindex(*localization_performance_len), loc_space_comb):\n",
    "        count_ij = dlp[(dlp.collision_rate_d == 0.5) & (dlp.absolute_translation_error_d == x_ate) & (dlp.normalized_relative_translation_error_d == x_nrte)]['collision_rate_d'].count()\n",
    "        total_ij = dlp[(dlp.absolute_translation_error_d == x_ate) & (dlp.normalized_relative_translation_error_d == x_nrte)]['collision_rate_d'].count()\n",
    "        p_cr_1 += p[i, j] * (count_ij / total_ij) if total_ij > 0 else 0\n",
    "    \n",
    "#     print(\"p_cr_0 + p_cr_1\", p_cr_0 + p_cr_1)\n",
    "    p_cr_1 = p_cr_1 / (p_cr_0 + p_cr_1)\n",
    "    \n",
    "    p_cr_1_gt = d_gt_all['collision_rate'].mean()\n",
    "    \n",
    "    return p_cr_1, p_cr_1_gt\n",
    "\n",
    "# amcl_alpha_factor_values = [1.0]\n",
    "amcl_alpha_factor_values = [0.5, 1.0, 2.0]\n",
    "beta_1_values = [0.02, 0.05, 0.1]\n",
    "# for smoothing_value in np.linspace(0.00001, 0.001, 100):\n",
    "for smoothing_value in [0.0]:\n",
    "    for amcl_alpha_factor in amcl_alpha_factor_values:\n",
    "        fig = plt.figure()\n",
    "        beta_1_y_p_cr_1 = list()\n",
    "        beta_1_y_data = list()\n",
    "        for beta_1 in beta_1_values:\n",
    "            p_cr_1, p_cr_1_gt = compute_joint_cr(amcl_alpha_factor, beta_1, smoothing_value=smoothing_value)\n",
    "            beta_1_y_p_cr_1.append(p_cr_1)\n",
    "            beta_1_y_data.append(p_cr_1_gt)\n",
    "        plt.plot(beta_1_values, beta_1_y_p_cr_1, '.-', label=f\"p_cr_1, amcl_alpha_factor={amcl_alpha_factor}\")\n",
    "        plt.plot(beta_1_values, beta_1_y_data, '.--', label=f\"data, amcl_alpha_factor={amcl_alpha_factor}\")\n",
    "\n",
    "        plt.grid()\n",
    "        plt.legend(bbox_to_anchor=(1.04, 1), borderaxespad=0)\n",
    "        plt.xlabel(\"beta_1\")\n",
    "        plt.ylabel(f\"{'collision_rate'.replace('_', ' ')} from joint dist (x_ate, x_nrte)\")\n",
    "        plt.ylim([0, 1])\n",
    "        fig.set_size_inches([3, 3])\n",
    "#         plt.savefig(f\"plots/smoothing/ate_nrte___amcl_{int(amcl_alpha_factor*10)}_smoothing_{int(smoothing_value*1000000)}.png\")\n",
    "#         plt.close()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
